# nf-core/saliva: Output

## Introduction

This document describes the output produced by the pipeline.

The directories listed below will be created in the results directory after the pipeline has finished. All paths are relative to the top-level results directory.

## Pipeline overview

The pipeline is built using [Nextflow](https://www.nextflow.io/) and processes data using the following steps:

- [Gencove](#gencove) - Download data from your projects in Gencove
- [VCFtools](#vcftools) - Filter VCF samples by specified IDs
- [PLINK VCF](#plinkvcf) - Create PLINK binary sets from VCFs
- [Upload Mongo](#uploadmongo) - Upload specific information from the filtered VCFs and other data to MongoDB
- [TileDB VCF Store](#tiledbvcf) - Store VCFs in TileDB
- [Pipeline information](#pipeline-information) - Report metrics generated during the workflow execution

### Gencove

<details markdown="1">
<summary>Output files</summary>

- `gencove/`
  - `*_.json`: Different types of JSON files available for your project
  - `*_.vcf.gz`: VCF of your samples at your project in Gencove.
  - `*_.tbi`: TBI of your samples at your project in Gencove.

</details>

### VCFtools

<details markdown="1">
<summary>Output files</summary>

- `vcftools/`
  - `*recode.vcf`: a VCF with filtered variants.

</details>

### PLINK VCF

<details markdown="1">
<summary>Output files</summary>

- `plink/`
  - `*.bed`: BED PLINK files
  - `*.bim`: BIM PLINK files
  - `*.fam`: FAM PLINK files

 ### MongoDB

<details markdown="1">
<summary>Output files</summary>

Data is stored using a custom script in your desired MongoDB .

  ### TileDB VCF

<details markdown="1">
<summary>Output files</summary>

- `tiledbvcf/`

Data is stored in your desired TileDB VCF.


### Pipeline information

<details markdown="1">
<summary>Output files</summary>

- `pipeline_info/`
  - Reports generated by Nextflow: `execution_report.html`, `execution_timeline.html`, `execution_trace.txt` and `pipeline_dag.dot`/`pipeline_dag.svg`.
  - Reports generated by the pipeline: `pipeline_report.html`, `pipeline_report.txt` and `software_versions.yml`. The `pipeline_report*` files will only be present if the `--email` / `--email_on_fail` parameter's are used when running the pipeline.
  - Reformatted samplesheet files used as input to the pipeline: `samplesheet.valid.csv`.

</details>

[Nextflow](https://www.nextflow.io/docs/latest/tracing.html) provides excellent functionality for generating various reports relevant to the running and execution of the pipeline. This will allow you to troubleshoot errors with the running of the pipeline, and also provide you with other information such as launch commands, run times and resource usage.
